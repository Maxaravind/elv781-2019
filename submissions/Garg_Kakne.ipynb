{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aryam\\Anaconda2\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "import scipy.interpolate\n",
    "\n",
    "def xi(x):\n",
    "    return (1+1./(1.+np.exp(-20.*(x-1./3.))))\n",
    "\n",
    "def tau(x, xi):\n",
    "    val = 1\n",
    "    for y in x:\n",
    "        val = val*xi(y)\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd;\n",
    "data1980 = pd.read_csv('m_d_806.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(428951, 85)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np;\n",
    "Y = data1980[data1980.AGEM<=35];\n",
    "Y = Y[Y.AGEM>=21];\n",
    "Y = Y[Y.KIDCOUNT>=2];\n",
    "Y = Y[Y.AGEQ2ND>=4];\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean is:  0.5632344953153158\n",
      "The STD is: 0.49598585876907014\n"
     ]
    }
   ],
   "source": [
    "Y1 = (Y.WEEKSM.dropna()>0).dropna();\n",
    "print 'The mean is: ',Y1.mean()\n",
    "print 'The STD is:', Y1.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean is:  0.5661555033011633\n",
      "The STD is: 0.4956047214741414\n"
     ]
    }
   ],
   "source": [
    "Y2 = Y[Y.TIMESMAR.dropna()>0].WEEKSM.dropna()>0;\n",
    "print 'The mean is: ',Y2.mean()\n",
    "print 'The STD is:', Y2.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean is:  0.9729730477766768\n",
      "The STD is: 0.16216216839580402\n"
     ]
    }
   ],
   "source": [
    "Y3 = Y.WEEKSD.dropna()>0;\n",
    "print 'The mean is: ',Y3.mean()\n",
    "print 'The STD is:', Y3.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean is:  20.666505032\n",
      "The STD is: 22.2365411866\n"
     ]
    }
   ],
   "source": [
    "Y4 = Y.WEEKSM.dropna();\n",
    "print 'The mean is: ',Y4.mean()\n",
    "print 'The STD is:', Y4.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean is:  20.7887976841\n",
      "The STD is: 22.2449489973\n"
     ]
    }
   ],
   "source": [
    "Y5 = Y[Y.TIMESMAR>0].WEEKSM.dropna();\n",
    "print 'The mean is: ',Y5.mean()\n",
    "print 'The STD is:', Y5.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean is:  47.39468207\n",
      "The STD is: 11.2378905509\n"
     ]
    }
   ],
   "source": [
    "Y6 = Y.WEEKSD.dropna();\n",
    "print 'The mean is: ',Y6.mean()\n",
    "print 'The STD is:', Y6.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean is:  18.7538017163\n",
      "The STD is: 18.9337119334\n"
     ]
    }
   ],
   "source": [
    "Y7 = Y.HOURSM.dropna();\n",
    "print 'The mean is: ',Y7.mean()\n",
    "print 'The STD is:', Y7.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean is:  18.8135552061\n",
      "The STD is: 18.9077721081\n"
     ]
    }
   ],
   "source": [
    "Y8 = Y[Y.TIMESMAR>0].HOURSM.dropna();\n",
    "print 'The mean is: ',Y8.mean()\n",
    "print 'The STD is:', Y8.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean is:  43.1116366736\n",
      "The STD is: 12.5962779687\n"
     ]
    }
   ],
   "source": [
    "Y9 = Y.HOURSD.dropna();\n",
    "print 'The mean is: ',Y9.mean()\n",
    "print 'The STD is:', Y9.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean is:  7113.17240341\n",
      "The STD is: 10780.203499\n"
     ]
    }
   ],
   "source": [
    "Y10 = ((pd.Series(x for x in Y.INCOME1M)  + pd.Series(max(0,y) for y in Y.INCOME2M))*2.099173554).dropna();\n",
    "Y10.index = Y1.index\n",
    "print 'The mean is: ',Y10.mean()\n",
    "print 'The STD is:', Y10.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean is:  7158.75754568\n",
      "The STD is: 10804.9067613\n"
     ]
    }
   ],
   "source": [
    "Y11 = ((pd.Series(x for x in Y[Y.TIMESMAR>0].INCOME1M)  + pd.Series(max(0,y) for y in Y[Y.TIMESMAR>0].INCOME2M))*2.099173554).dropna();\n",
    "Y11.index = Y2.index;\n",
    "print 'The mean is: ',Y11.mean()\n",
    "print 'The STD is:', Y11.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean is:  37178.4893897\n",
      "The STD is: 24535.7932891\n"
     ]
    }
   ],
   "source": [
    "Y12 = ((pd.Series(x for x in Y.INCOME1D)  + pd.Series(max(0,y) for y in Y.INCOME2D))*2.099173554).dropna();\n",
    "Y12.index = Y3.index;\n",
    "print 'The mean is: ',Y12.mean()\n",
    "print 'The STD is:', Y12.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean is:  10.3028235718\n",
      "The STD is: 1.36638171028\n"
     ]
    }
   ],
   "source": [
    "Ytemp = Y.FAMINC*2.099173554;\n",
    "Y13 = np.log(pd.Series(max(1,x) for x in Ytemp))\n",
    "Y13.index = Y.index;\n",
    "print 'The mean is: ',Y13.mean()\n",
    "print 'The STD is:', Y13.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean is:  10.3493584142\n",
      "The STD is: 1.31080402469\n"
     ]
    }
   ],
   "source": [
    "Ytemp = Y.FAMINC[Y.TIMESMAR>0]*2.099173554;\n",
    "Y14 = np.log(pd.Series(max(1,x) for x in Ytemp))\n",
    "Y14.index = Y2.index;\n",
    "print 'The mean is: ',Y14.mean()\n",
    "print 'The STD is:', Y14.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean is:  9.78610058889\n",
      "The STD is: 2.32820877613\n"
     ]
    }
   ],
   "source": [
    "Ytemp = ((Y.FAMINC[Y.TIMESMAR>0] - Y[Y.TIMESMAR>0].INCOME1M)*2.099173554);\n",
    "Ytemp2 = pd.Series(max(1,x) for x in Ytemp);\n",
    "Y15 = np.log(Ytemp2)\n",
    "Y15.index = Y2.index;\n",
    "print 'The mean is: ',Y15.mean()\n",
    "print 'The STD is:', Y15.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X1M = Y.AGEM\n",
    "X1D = Y.AGED.dropna();\n",
    "X1MAR = X1M[Y.TIMESMAR>0];\n",
    "X2M = Y.AGEM - Y.AGEK\n",
    "X2D = (Y.AGED - Y.AGEK).dropna();\n",
    "X2MAR = X2M[Y.TIMESMAR>0];\n",
    "X3M = pd.Series(index = Y.index);\n",
    "X3D = pd.Series(index= Y3.index);\n",
    "for i in Y.index:\n",
    "    if(Y.loc[i].FINGRADM==2 or Y.loc[i].FINGRADM==1):\n",
    "        X3M.loc[i] = max(0,Y.GRADEM.loc[i] - 2);\n",
    "    else:\n",
    "        X3M.loc[i] = max(0,Y.GRADEM.loc[i] - 3);\n",
    "for i in Y3.index:\n",
    "    if(Y.loc[i].FINGRADD==2 or Y.loc[i].FINGRADD==1):\n",
    "        X3D.loc[i] = max(0,Y.GRADED.loc[i] - 2);\n",
    "    else:\n",
    "        X3D.loc[i] = max(0,Y.GRADED.loc[i] - 3);\n",
    "X3MAR = X3M[Y.TIMESMAR>0];\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X4M = Y.RACEM==1\n",
    "X4D = (Y.RACED.dropna()==1)\n",
    "X4MAR = X4M[Y.TIMESMAR>0];\n",
    "X5M = Y.RACEM==2\n",
    "X5D = (Y.RACED.dropna()==2)\n",
    "X5MAR = X5M[Y.TIMESMAR>0];\n",
    "X6M = Y.RACEM==12\n",
    "X6D = Y.RACED.dropna()==12\n",
    "X6MAR = X6M[Y.TIMESMAR>0];\n",
    "X7M = ((1-X4M)&(1-X5M)&(1-X6M)).astype(bool)\n",
    "X7D = ((1-X4D)&(1-X5D)&(1-X6D)).astype(bool)\n",
    "X7MAR = X7M[Y.TIMESMAR>0];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XM = pd.DataFrame({'X1':X1M,'X2':X2M,'X3':X3M,'X4':X4M,'X5':X5M,'X6':X6M,'X7':X7M},index = X1M.index);\n",
    "XD = pd.DataFrame({'X1':X1D,'X2':X2D,'X3':X3D,'X4':X4D,'X5':X5D,'X6':X6D,'X7':X7D},index = X1D.index);\n",
    "XMAR = pd.DataFrame({'X1':X1MAR,'X2':X2MAR,'X3':X3MAR,'X4':X4MAR,'X5':X5MAR,'X6':X6MAR,'X7':X7MAR},index = X1MAR.index);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XM_ols = sm.add_constant(XM)\n",
    "XD_ols = sm.add_constant(XD)\n",
    "XMAR_ols = sm.add_constant(XMAR)\n",
    "\n",
    "est1 = sm.OLS(Y1.values,XM_ols.astype(float).values);\n",
    "est2 = sm.OLS(Y2.values,XMAR_ols.astype(float).values);\n",
    "est3 = sm.OLS(Y3.values,XD_ols.astype(float).values);\n",
    "est4 = sm.OLS(Y4.values,XM_ols.astype(float).values);\n",
    "est5 = sm.OLS(Y5.values,XMAR_ols.astype(float).values);\n",
    "est6 = sm.OLS(Y6.values,XD_ols.astype(float).values);\n",
    "est7 = sm.OLS(Y7.values,XM_ols.astype(float).values);\n",
    "est8 = sm.OLS(Y8.values,XMAR_ols.astype(float).values);\n",
    "est9 = sm.OLS(Y9.values,XD_ols.astype(float).values);\n",
    "est10 = sm.OLS(Y10.values,XM_ols.astype(float).values);\n",
    "est11 = sm.OLS(Y11.values,XMAR_ols.astype(float).values);\n",
    "est12 = sm.OLS(Y12.values,XD_ols.astype(float).values);\n",
    "est13 = sm.OLS(Y13.values,XM_ols.astype(float).values);\n",
    "est14 = sm.OLS(Y14.values,XMAR_ols.astype(float).values);\n",
    "est15 = sm.OLS(Y15.values,XMAR_ols.astype(float).values);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est1 = est1.fit();\n",
    "est2 = est2.fit();\n",
    "est3 = est3.fit();\n",
    "est4 = est4.fit();\n",
    "est5 = est5.fit();\n",
    "est6 = est6.fit();\n",
    "est7 = est7.fit();\n",
    "est8 = est8.fit();\n",
    "est9 = est9.fit();\n",
    "est10 = est10.fit();\n",
    "est11 = est11.fit();\n",
    "est12 = est12.fit();\n",
    "est13 = est13.fit();\n",
    "est14 = est14.fit();\n",
    "est15 = est15.fit();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est3.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est4.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est5.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "est6.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "est7.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "est8.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "est9.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "est10.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "est11.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "est12.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "est13.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "est14.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "est15.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Sample_indexM = random.sample(XM.index,len(XM))\n",
    "Sample_indexD = random.sample(XD.index,len(XD))\n",
    "Sample_indexMAR = random.sample(XMAR.index,len(XMAR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation_data_index1 = random.sample(Sample_indexM, np.int(np.ceil(len(XM)*0.1)))\n",
    "Evaluation_data_xi1 = XM.loc[Evaluation_data_index1]\n",
    "Evaluation_data_target1 = Y1.loc[Evaluation_data_index1]\n",
    "Training_data_index1 = list(set(Sample_indexM)-set(Evaluation_data_index1))\n",
    "Training_data_target1 = Y1.loc[Training_data_index1]\n",
    "Training_data_xi1 = XM.loc[Training_data_index1]\n",
    "clf1 = tree.DecisionTreeRegressor(criterion='mse')\n",
    "clf1 = clf1.fit(Training_data_xi1, Training_data_target1)\n",
    "\n",
    "tau_hat1 = clf1.predict(Evaluation_data_xi1)\n",
    "\n",
    "print(clf1.score(Evaluation_data_xi1, Evaluation_data_target1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation_data_index2 = random.sample(Sample_indexMAR, np.int(np.ceil(len(XMAR)*0.1)))\n",
    "Evaluation_data_xi2 = XMAR.loc[Evaluation_data_index2]\n",
    "Evaluation_data_target2 = Y2.loc[Evaluation_data_index2]\n",
    "Training_data_index2 = list(set(Sample_indexMAR)-set(Evaluation_data_index2))\n",
    "Training_data_target2 = Y2.loc[Training_data_index2]\n",
    "Training_data_xi2 = XM.loc[Training_data_index2]\n",
    "clf2 = tree.DecisionTreeRegressor(criterion='mse')\n",
    "clf2 = clf2.fit(Training_data_xi2, Training_data_target2)\n",
    "\n",
    "tau_hat2 = clf2.predict(Evaluation_data_xi2)\n",
    "\n",
    "print(clf2.score(Evaluation_data_xi2, Evaluation_data_target2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation_data_index3 = random.sample(Sample_indexD, np.int(np.ceil(len(XD)*0.1)))\n",
    "Evaluation_data_xi3 = XD.loc[Evaluation_data_index3]\n",
    "Evaluation_data_target3 = Y3.loc[Evaluation_data_index3]\n",
    "Training_data_index3 = list(set(Sample_indexD)-set(Evaluation_data_index3))\n",
    "Training_data_target3 = Y3.loc[Training_data_index3]\n",
    "Training_data_xi3 = XD.loc[Training_data_index3]\n",
    "clf3 = tree.DecisionTreeRegressor(criterion='mse')\n",
    "clf3 = clf3.fit(Training_data_xi3, Training_data_target3)\n",
    "\n",
    "tau_hat3 = clf3.predict(Evaluation_data_xi3)\n",
    "\n",
    "print(clf3.score(Evaluation_data_xi3, Evaluation_data_target3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation_data_index4 = random.sample(Sample_indexM, np.int(np.ceil(len(XM)*0.1)))\n",
    "Evaluation_data_xi4 = XM.loc[Evaluation_data_index4]\n",
    "Evaluation_data_target4 = Y4.loc[Evaluation_data_index4]\n",
    "Training_data_index4 = list(set(Sample_indexM)-set(Evaluation_data_index4))\n",
    "Training_data_target4 = Y4.loc[Training_data_index4]\n",
    "Training_data_xi4 = XM.loc[Training_data_index4]\n",
    "clf4 = tree.DecisionTreeRegressor(criterion='mse')\n",
    "clf4 = clf4.fit(Training_data_xi4, Training_data_target4)\n",
    "\n",
    "tau_hat4 = clf4.predict(Evaluation_data_xi4)\n",
    "\n",
    "print(clf4.score(Evaluation_data_xi4, Evaluation_data_target4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation_data_index5 = random.sample(Sample_indexMAR, np.int(np.ceil(len(XMAR)*0.1)))\n",
    "Evaluation_data_xi5 = XMAR.loc[Evaluation_data_index5]\n",
    "Evaluation_data_target5 = Y5.loc[Evaluation_data_index5]\n",
    "Training_data_index5= list(set(Sample_indexMAR)-set(Evaluation_data_index5))\n",
    "Training_data_target5 = Y5.loc[Training_data_index5]\n",
    "Training_data_xi5 = XM.loc[Training_data_index5]\n",
    "clf5 = tree.DecisionTreeRegressor(criterion='mse')\n",
    "clf5 = clf5.fit(Training_data_xi5, Training_data_target5)\n",
    "\n",
    "tau_hat5 = clf5.predict(Evaluation_data_xi5)\n",
    "\n",
    "print(clf5.score(Evaluation_data_xi5, Evaluation_data_target5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation_data_index6 = random.sample(Sample_indexD, np.int(np.ceil(len(XD)*0.1)))\n",
    "Evaluation_data_xi6 = XD.loc[Evaluation_data_index6]\n",
    "Evaluation_data_target6 = Y6.loc[Evaluation_data_index6]\n",
    "Training_data_index6 = list(set(Sample_indexD)-set(Evaluation_data_index6))\n",
    "Training_data_target6 = Y6.loc[Training_data_index6]\n",
    "Training_data_xi6 = XD.loc[Training_data_index6]\n",
    "clf6 = tree.DecisionTreeRegressor(criterion='mse')\n",
    "clf6 = clf6.fit(Training_data_xi6, Training_data_target6)\n",
    "\n",
    "tau_hat6 = clf6.predict(Evaluation_data_xi6)\n",
    "\n",
    "print(clf6.score(Evaluation_data_xi6, Evaluation_data_target6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation_data_index7 = random.sample(Sample_indexM, np.int(np.ceil(len(XM)*0.1)))\n",
    "Evaluation_data_xi7 = XM.loc[Evaluation_data_index4]\n",
    "Evaluation_data_target7 = Y7.loc[Evaluation_data_index7]\n",
    "Training_data_index7 = list(set(Sample_indexM)-set(Evaluation_data_index7))\n",
    "Training_data_target7 = Y7.loc[Training_data_index7]\n",
    "Training_data_xi7 = XM.loc[Training_data_index7]\n",
    "clf7 = tree.DecisionTreeRegressor(criterion='mse')\n",
    "clf7 = clf7.fit(Training_data_xi7, Training_data_target7)\n",
    "\n",
    "tau_hat7 = clf7.predict(Evaluation_data_xi7)\n",
    "\n",
    "print(clf7.score(Evaluation_data_xi7, Evaluation_data_target7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation_data_index8 = random.sample(Sample_indexMAR, np.int(np.ceil(len(XMAR)*0.1)))\n",
    "Evaluation_data_xi8 = XMAR.loc[Evaluation_data_index8]\n",
    "Evaluation_data_target8 = Y8.loc[Evaluation_data_index8]\n",
    "Training_data_index8 = list(set(Sample_indexMAR)-set(Evaluation_data_index8))\n",
    "Training_data_target8 = Y8.loc[Training_data_index8]\n",
    "Training_data_xi8 = XM.loc[Training_data_index8]\n",
    "clf8 = tree.DecisionTreeRegressor(criterion='mse')\n",
    "clf8 = clf8.fit(Training_data_xi8, Training_data_target8)\n",
    "\n",
    "tau_hat8 = clf8.predict(Evaluation_data_xi8)\n",
    "\n",
    "print(clf8.score(Evaluation_data_xi8, Evaluation_data_target8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation_data_index9 = random.sample(Sample_indexD, np.int(np.ceil(len(XD)*0.1)))\n",
    "Evaluation_data_xi9 = XD.loc[Evaluation_data_index9]\n",
    "Evaluation_data_target9 = Y9.loc[Evaluation_data_index9]\n",
    "Training_data_index9 = list(set(Sample_indexD)-set(Evaluation_data_index9))\n",
    "Training_data_target9 = Y9.loc[Training_data_index9]\n",
    "Training_data_xi9 = XD.loc[Training_data_index9]\n",
    "clf9 = tree.DecisionTreeRegressor(criterion='mse')\n",
    "clf9 = clf9.fit(Training_data_xi9, Training_data_target9)\n",
    "\n",
    "tau_hat9 = clf9.predict(Evaluation_data_xi9)\n",
    "\n",
    "print(clf9.score(Evaluation_data_xi9, Evaluation_data_target9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation_data_index10 = random.sample(Sample_indexM, np.int(np.ceil(len(XM)*0.1)))\n",
    "Evaluation_data_xi10 = XM.loc[Evaluation_data_index4]\n",
    "Evaluation_data_target10 = Y10.loc[Evaluation_data_index10]\n",
    "Training_data_index10 = list(set(Sample_indexM)-set(Evaluation_data_index10))\n",
    "Training_data_target10 = Y10.loc[Training_data_index10]\n",
    "Training_data_xi10 = XM.loc[Training_data_index10]\n",
    "clf10 = tree.DecisionTreeRegressor(criterion='mse')\n",
    "clf10 = clf10.fit(Training_data_xi10, Training_data_target10)\n",
    "\n",
    "tau_hat10 = clf10.predict(Evaluation_data_xi10)\n",
    "\n",
    "print(clf10.score(Evaluation_data_xi10, Evaluation_data_target10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation_data_index11 = random.sample(Sample_indexMAR, np.int(np.ceil(len(XMAR)*0.1)))\n",
    "Evaluation_data_xi11 = XMAR.loc[Evaluation_data_index11]\n",
    "Evaluation_data_target11 = Y11.loc[Evaluation_data_index11]\n",
    "Training_data_index11 = list(set(Sample_indexMAR)-set(Evaluation_data_index11))\n",
    "Training_data_target11 = Y11.loc[Training_data_index11]\n",
    "Training_data_xi11 = XM.loc[Training_data_index11]\n",
    "clf11 = tree.DecisionTreeRegressor(criterion='mse')\n",
    "clf11 = clf11.fit(Training_data_xi11, Training_data_target11)\n",
    "\n",
    "tau_hat11 = clf11.predict(Evaluation_data_xi11)\n",
    "\n",
    "print(clf11.score(Evaluation_data_xi11, Evaluation_data_target11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation_data_index12 = random.sample(Sample_indexD, np.int(np.ceil(len(XD)*0.1)))\n",
    "Evaluation_data_xi12 = XD.loc[Evaluation_data_index12]\n",
    "Evaluation_data_target12 = Y12.loc[Evaluation_data_index12]\n",
    "Training_data_index12 = list(set(Sample_indexD)-set(Evaluation_data_index12))\n",
    "Training_data_target12 = Y12.loc[Training_data_index12]\n",
    "Training_data_xi12 = XD.loc[Training_data_index12]\n",
    "clf12 = tree.DecisionTreeRegressor(criterion='mse')\n",
    "clf12 = clf12.fit(Training_data_xi12, Training_data_target12)\n",
    "\n",
    "tau_hat12 = clf12.predict(Evaluation_data_xi12)\n",
    "\n",
    "print(clf12.score(Evaluation_data_xi12, Evaluation_data_target12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation_data_index13 = random.sample(Sample_indexM, np.int(np.ceil(len(XM)*0.1)))\n",
    "Evaluation_data_xi13 = XM.loc[Evaluation_data_index4]\n",
    "Evaluation_data_target13 = Y13.loc[Evaluation_data_index13]\n",
    "Training_data_index13 = list(set(Sample_indexM)-set(Evaluation_data_index13))\n",
    "Training_data_target13 = Y13.loc[Training_data_index13]\n",
    "Training_data_xi13 = XM.loc[Training_data_index13]\n",
    "clf13 = tree.DecisionTreeRegressor(criterion='mse')\n",
    "clf13 = clf13.fit(Training_data_xi13, Training_data_target13)\n",
    "\n",
    "tau_hat13 = clf13.predict(Evaluation_data_xi13)\n",
    "\n",
    "print(clf13.score(Evaluation_data_xi13, Evaluation_data_target13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation_data_index14 = random.sample(Sample_indexMAR, np.int(np.ceil(len(XMAR)*0.1)))\n",
    "Evaluation_data_xi14 = XMAR.loc[Evaluation_data_index14]\n",
    "Evaluation_data_target14 = Y14.loc[Evaluation_data_index14]\n",
    "Training_data_index14 = list(set(Sample_indexMAR)-set(Evaluation_data_index14))\n",
    "Training_data_target14 = Y14.loc[Training_data_index14]\n",
    "Training_data_xi14 = XM.loc[Training_data_index14]\n",
    "clf14 = tree.DecisionTreeRegressor(criterion='mse')\n",
    "clf14 = clf14.fit(Training_data_xi14, Training_data_target14)\n",
    "\n",
    "tau_hat14 = clf14.predict(Evaluation_data_xi14)\n",
    "\n",
    "print(clf14.score(Evaluation_data_xi14, Evaluation_data_target14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation_data_index15 = random.sample(Sample_indexMAR, np.int(np.ceil(len(XMAR)*0.1)))\n",
    "Evaluation_data_xi15 = XMAR.loc[Evaluation_data_index15]\n",
    "Evaluation_data_target15 = Y15.loc[Evaluation_data_index15]\n",
    "Training_data_index15 = list(set(Sample_indexMAR)-set(Evaluation_data_index15))\n",
    "Training_data_target15 = Y15.loc[Training_data_index15]\n",
    "Training_data_xi15 = XM.loc[Training_data_index15]\n",
    "clf15 = tree.DecisionTreeRegressor(criterion='mse')\n",
    "clf15 = clf15.fit(Training_data_xi15, Training_data_target15)\n",
    "\n",
    "tau_hat15 = clf15.predict(Evaluation_data_xi15)\n",
    "\n",
    "print(clf15.score(Evaluation_data_xi15, Evaluation_data_target15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
